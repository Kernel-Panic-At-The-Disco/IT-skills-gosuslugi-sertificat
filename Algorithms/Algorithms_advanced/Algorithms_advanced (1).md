# **Algorithms\_advanced**

**Вопрос 1**

Вы работаете с распределенной системой, которая обрабатывает миллионы записей. При попытке внедрить быструю сортировку (quicksort) в условиях параллельной обработки на нескольких узлах результаты оказались нестабильными. Время выполнения варьируется, и на некоторых узлах наблюдается перегрузка памяти.

Какой подход следует выбрать, чтобы обеспечить детерминированное поведение и равномерную нагрузку при масштабировании сортировки?

1. Использовать параллельное слияние после завершения сортировки на каждом узле  
2. Включить механизм кеширования на уровне системы ввода-вывода  
3. Настроить сбалансированное распределение нагрузки между узлами  
4. Выбрать алгоритм сортировки слиянием для его детерминированности  
5. Переходить на более мелкие пакеты данных и выполнять их последовательную сортировку

**Вопрос 2**

Вы разрабатываете систему поиска в структуре данных с динамическими изменениями, такой как граф или дерево, где необходимо учитывать изменяющуюся структуру.

Вы определили для себя такие условия:

1. Количество узлов может достигать 100 миллионов, и связи между узлами изменяются в реальном времени  
2. Алгоритм поиска должен минимизировать затраты на обновление структуры данных  
3. Важно учитывать динамические изменения при выборе наиболее подходящего метода поиска

Что применить, чтобы обеспечить наилучшую производительность при этих условиях?

1. Применять жадный алгоритм (например, жадный поиск А) без учета изменений структуры  
2. Оценить стоимость всех возможных путей в графе с учетом возможных циклов и их влияния на скорость поиска  
3. Учитывать сложность динамических изменений структуры данных и выбирать алгоритм, минимизирующий затраты на обновления  
4. Рассматривать использование многократных индексаций и предварительных вычислений для ускорения поиска  
5. Выбирать алгоритм, который будет эффективен только при статической структуре данных

**Вопрос 3**

В вашем проекте требуется организовать структуру данных для эффективного выполнения операций поиска, добавления и удаления элементов при высоких нагрузках.

Вам известно следующее:

1. Объем данных превышает 10 миллионов записей  
2. Система ограничена в оперативной памяти (не более 1 ГБ)  
3. Средняя нагрузка 100 тысяч операций в минуту  
4. Требуется минимизировать задержки при поиске и обновлении данных

Почему в условиях этого сценария хеш-таблица может оказаться неидеальным решением, несмотря на высокую скорость выполнения операций?

1. Хеш-таблица требует хранения хешей и связей, что увеличивает потребление памяти, особенно при использовании методов открытой адресации  
2. Поиск в хеш-таблице невозможен без точного знания ключа, что усложняет обработку данных с иерархической структурой  
3. Значительные накладные расходы на разрешение коллизий могут привести к росту времени поиска в худших случаях  
4. Хеш-таблица увеличивает время доступа к данным в условиях конкурентного использования памяти с множеством параллельных потоков  
5. Упорядоченный обход элементов невозможен, что делает хеш-таблицы неэффективными в задачах, требующих итерационного поиска по диапазону

**Вопрос 4**

В многопоточной системе обработки данных после внедрения нового механизма управления потоками была зафиксирована следующая ситуация:

Пропускная способность значительно возросла, но при этом:

* Некоторые потоки стали получать приоритетный доступ к данным, вызывая неравномерную загрузку ресурсов.  
* Система стала более сложной в отладке из\-за трудностей в выявлении ошибок конкурентного доступа.

Какие шаги могли привести к такому результату?

1. Оптимизация алгоритма синхронизации за счет сокращения количества блокировок и упрощение механизма проверки состояния потоков  
2. Удаление блокировок при доступе к данным и переход на lock-free очередь без учета возможных гонок данных  
3. Переработка структуры очереди с целью уменьшения накладных расходов на ожидание и внедрение механизма атомарного обновления данных  
4. Введение стратегии динамического перераспределения потоков и отказ от явных приоритетов доступа к ресурсам  
5. Замена стандартной mutex-based очереди на lock-free структуру и отказ от механизма балансировки нагрузки между потоками

**Вопрос 5**

В вашей компании, занимающейся анализом логов (журналов событий) с нескольких серверов, долгое время применялся метод опорных векторов (SVM) для классификации записей.

Однако объемы данных продолжали расти, и вы решили перейти на логистическую регрессию, чтобы ускорить процесс обучения и упростить масштабирование. По результатам тестов выяснилось, что логистическая регрессия действительно обучается быстрее, но итоговая точность может заметно колебаться в зависимости от структуры и размера поступающих логов.

С учетом того, что решение принималось не как выбор ML-модели, а как архитектурная замена ресурсоемкого алгоритма на более масштабируемый, в чем причина таких изменений?

1. Логистическая регрессия сильно зависит от линейной разделимости данных, и если данные не линейно разделимы, точность меняется в зависимости от структуры и размера логов  
2. Логистическая регрессия автоматически масштабирует признаки и всегда работает с изменчивой точностью за O(logn), независимо от структуры данных  
3. Логистическая регрессия требует значительно большего объема памяти при работе с большими логами, что негативно влияет на точность модели  
4. Логистическая регрессия по определению применима только к симметрично распределённым данным и не может адаптироваться к неравномерной выборке  
5. Логистическая регрессия не учитывает размер выборки и сохраняет постоянно колеблющуюся точность при обучении независимо от объема и размера логов

**Вопрос 6**

Ваше приложение обрабатывает миллиарды записей в реальном времени, но система неожиданно начала потреблять больше памяти, чем было рассчитано. Логирование показало, что значительная часть памяти уходит на накладные расходы структуры данных.

Что наиболее вероятно приводит к повышенному расходу памяти?

1. Ограничение числа одновременно загруженных структур данных  
2. Использование сжатия данных  
3. Использование деревьев поиска вместо хеш-таблиц  
4. Применение memory-mapped файлов  
5. Замена динамического выделения памяти на статическое

**Вопрос 7**

Вы реализуете рекурсивный алгоритм, однако с увеличением глубины рекурсии происходит значительное замедление и превышение лимита стека. В некоторых случаях выполнение завершается с ошибкой переполнения памяти.

Что является наиболее вероятной причиной этой проблемы?

1. Рекурсивные вызовы без оптимизированного условия выхода приводят к увеличению глубины стека  
2. Использование глобальных переменных для хранения промежуточных результатов может увеличивать потребление памяти  
3. Передача большого массива в рекурсивные вызовы увеличивает накладные расходы  
4. Чрезмерная глубина рекурсии без мемоизации приводит к переполнению стека  
5. Неэффективное выделение памяти для локальных переменных может привести к увеличению потребления ресурсов

**Вопрос 8**

Вы анализируете логи работы алгоритма Дейкстры, используемого в навигационной системе умного города. Полученные маршруты вызывают сомнения, и вам нужно определить, соответствует ли структура графа требованиям алгоритма.

В вашей программе после выполнения алгоритма Дейкстры лог системы вывел следующий путь: А → С → F → H → G

Какие выводы можно сделать о структуре графа и корректности работы алгоритма, основываясь на данном маршруте?

1. Граф направленный, все ребра имеют положительные веса, а сам алгоритм отработал корректно  
2. Маршрут мог быть построен некорректно из\-за возможного наличия циклов в графе  
3. Один выбранный маршрут не дает полной информации о числе связей у вершин графа  
4. Наличие отрицательных ребер могло бы привести к ошибкам в алгоритме Дейкстры  
5. Алгоритм Дейкстры использует жадный метод, выбирая ближайшую вершину на каждом шаге пути

**Вопрос 9**

Вы разрабатываете распределенную систему обработки данных, в которой хеш-таблица используется для быстрого доступа к записи журнала событий. После развертывания на тестовом окружении было выявлено, что время поиска отдельных записей значительно увеличивается по мере накопления данных. Дополнительный анализ показал, что в таблице образуется несколько «горячих» бакетов, содержащих непропорционально большое число элементов, что приводит к росту времени поиска.

Какой фактор вызывает такой рост?

1. Применение связных списков внутри бакетов исключает возможность накопления элементов в одном сегменте  
2. Использование плохой хеш-функции, приводящей к неравномерному распределению ключей  
3. Добавление большего количества бакетов приводит к сильному росту коллизий  
4. Рехеширование таблицы после каждой вставки значительно ускоряет доступ  
5. Ограничение глубины цепочек в методе цепочного хеширования

**Вопрос 10**

Выберите вариант ответа, в котором перечислены только ключевые метрики, определяющие производительность хеш-таблицы.

1. Частота рехеширования, глубина пробирования, общее число записей  
2. Коэффициент загрузки, количество коллизий, среднее время нахождения данных  
3. Распределение данных, максимальная длина цепочки, сложность хеш-функции  
4. Размер таблицы, количество операций вставки, использование связных списков  
5. Процент занятых ячеек, число доступных бакетов, время вычисления хеш-функции

**Вопрос 11**

В модуле сравнения текстов вы реализовали рекурсивную функцию, вычисляющую длину наибольшей общей подпоследовательности (LCS) для двух строк длиной до 10 000 символов каждая. Профилировщик показал, что функция тратит большую часть времени на повторные вычисления одних и тех же подзадач — например, многократно сравниваются одни и те же префиксы строк.

Какой приём позволит радикально сократить время работы алгоритма, сохранив корректный результат?

1. Использовать «жадный» выбор: сразу добавлять любой совпавший символ, если он встречается в обеих строках  
2. Ограничить глубину рекурсии фиксированным порогом, прерывая вычисления при его достижении  
3. Переписать алгоритм в итеративном стиле, полностью отказавшись от рекурсии, без хранения промежуточных результатов  
4. Кешировать только последние удачные совпадения символов, игнорируя остальные подзадачи  
5. Сохранять результаты уже решённых подзадач (мемоизация) и переиспользовать их при повторных вызовах

**Вопрос 12**

Вы разрабатываете систему навигации для транспортной компании, которая оптимизирует маршруты грузоперевозок между городами. Тестирование показало, что при увеличении количества точек доставки время расчета маршрутов резко возрастает, что приводит к задержкам в системе.

Как можно оптимизировать поиск маршрутов?

1. Применить алгоритм полного перебора, чтобы учесть все маршруты  
2. Удалить ребра с большим весом, чтобы сократить количество проверок  
3. Использовать алгоритм А\* с эвристиками для ускорения поиска  
4. Использовать DFS для поиска кратчайшего пути  
5. Настроить использование неориентированного графа вместо ориентированного

**Вопрос 13**

При решении задачи поиска длины наибольшей общей подпоследовательности (LCS) между двумя строками было замечено, что одни и те же подстроки сравниваются повторно. Это привело к существенному росту времени выполнения при увеличении длины строк.

Какой признак указывает на возможность применения динамического программирования в такой задаче?

1. Требует минимального времени, но допускает произвольный порядок вызова функций  
2. Должна быть линейной по используемой памяти и логарифмической по времени  
3. Допускает решение через уже строго отсортированный массив входных данных  
4. Не требует хранения промежуточных данных при любом подходе в их дальнейшей обработке  
5. Разбивается на перекрывающиеся подзадачи с возможностью переиспользования результатов

**Вопрос 14**

Какой алгоритм используется для построения минимального остовного дерева?

1. Алгоритм Дейкстры  
2. Алгоритм Беллмана-Форда  
3. Алгоритм А\* с эвристиками  
4. Алгоритм Флойда-Уоршелла  
5. Алгоритм Крускала

**Вопрос 15**

Какой метод НЕ является оптимальным для решения задачи линейного программирования с жесткими ограничениями?

1. Использование динамического программирования для разбиения задачи на подпроблемы  
2. Применение симплекс-метода для нахождения глобального оптимального решения  
3. Использование линейного поиска для нахождения допустимых значений переменных  
4. Применение метода градиентного спуска для оптимизации многомерных функций  
5. Использование жадного алгоритма, который принимает локально оптимальные решения на каждом шаге
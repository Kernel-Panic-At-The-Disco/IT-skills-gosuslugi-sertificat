# Algorithms_middle

## Вопрос 1  
У вас есть массив данных, который часто обновляется: добавляются новые элементы, удаляются устаревшие. Нужно поддерживать его частично отсортированным для ускорения выборки.  
Какой метод позволит наилучшим образом поддерживать частично отсортированный массив?  

- Применить сортировку вставками для поддержания порядка  
- Использовать двоичное дерево поиска с балансировкой  
- Сортировать весь массив после каждой вставки  
- Ограничить количество изменений и использовать полный пересчет массива  
- Применить алгоритм слияния для обновления массива  

---

## Вопрос 2  
Вы разрабатываете алгоритм для обработки огромных текстовых файлов. Задача — найти определенную подстроку в тексте с минимальными затратами времени.  
Какой из перечисленных алгоритмов применить, чтобы обеспечить наилучшую асимптотическую сложность при поиске подстроки?  

- Префиксное дерево \( O(nm) \)  
- Линейный поиск \( O(nm) \)  
- Алгоритм Рабина-Карпа \( O(n) \)  
- Кнут-Моррис-Пратт \( O(n) \)  
- Поиск с использованием кеш-таблиц \( O(log n) \)  

---

## Вопрос 3  
При разработке кэша в многопоточной системе разработчики обнаружили, что при одновременной записи нескольких потоков в хеш-таблицу некоторые записи теряются или изменяются некорректным образом.  
Выберите наиболее вероятное объяснение, почему это произошло:  

- Хеш-функция создает одинаковые значения для разных потоков, что приводит к перезаписи данных  
- Отсутствие механизма синхронизации привело к состояниям гонки при обновлении записей  
- Динамическое увеличение размера таблицы привело к тому, что старые записи стали недоступны  
- Удаление записей в многопоточной среде приводит к некорректному изменению связей между элементами  
- Таблица использует линейное пробирование, что увеличивает время поиска при большом количестве коллизий  

---

## Вопрос 4  
Вы разрабатываете многопоточное приложение, в котором стек используется для обработки данных.  
Дав высокую нагрузку на стек, вы замечаете некорректное поведение: некоторые элементы в стеке теряются или оказываются добавленными несколько раз.  
Выберите наиболее вероятное объяснение, почему это произошло:  

- Семафоры не обеспечивают последовательность выполнения операций, из-за чего при высокой конкуренции потоки могут некорректно изменять структуру данных  
- Мьютексы не предотвращают ситуации, когда несколько потоков одновременно изменяют стек, создавая возможность гонки данных  
- Барьеры памяти не гарантируют атомарность операций со стеком, что приводит к состояниям, когда один поток не видит обновлений, сделанных другим  
- Блокировки на уровне ядра замедляют выполнение и создают проблемы с корректностью работы многопоточного стека  
- Копирование при записи откладывает модификацию данных до записи, но не предотвращает одновременный доступ нескольких потоков  

---

## Вопрос 5  
В процессе работы с хеш-таблицей, использующей двойное хеширование для разрешения коллизий, разработчики заметили, что после удаления нескольких элементов время поиска оставшихся данных значительно увеличилось.  
По какой причине это могло произойти, если таблица имела высокий коэффициент загрузки и не выполнялось рехеширование после удаления записей?  

- Удаление элементов привело к изменению распределения всех хеш-значений, из-за чего поиск теперь требует больше шагов пробирования  
- Удаленные элементы оставили «дыры» в таблице, и двойное хеширование больше не может корректно переходить к следующим позициям  
- Каждое удаление требует перерасчёта всех хеш-значений, что увеличивает во много раз время поиска других оставшихся элементов таблицы  
- Из-за высокого коэффициента загрузки таблицы возросло число коллизий, что привело к значительному увеличению длины цепочек в бакетах  
- Двойное хеширование перезаписывает старые значения, что делает некоторые данные полностью недоступными после удаления записей  

---

## Вопрос 6  
Вы используете в алгоритме связный список для управления структурой очереди обработки задач. В какой-то момент оказалось, что в некоторых случаях задачи не достигают завершения.  
Что из перечисленного могло стать причиной такого поведения?  

- Отсутствие сортировки в хранимых данных  
- Случайное распределение данных в памяти  
- Ограниченный размер начального выделенного блока памяти  
- Неправильное обновление ссылок при удалении узлов  
- Низкая эффективность хеширования в больших структурах  

---

## Вопрос 7  
Какая техника оптимизации рекурсивных вызовов помогает избежать лишних вычислений?  

- «Разделяй и властвуй» для уменьшения накладных расходов  
- Мемоизация, позволяющая повторно использовать уже вычисленные значения  
- Оптимизация структуры данных с целью ускорения вычислений  
- Хеширование для ускорения поиска данных в рекурсивных вызовах  
- Использование глубокой рекурсии для сокращения количества шагов  

---

## Вопрос 8  
Какой из приведенных алгоритмов неэффективен при использовании рекурсии?  

- Факторизация числа, поскольку сложность разложения не зависит от многопоточности  
- Поиск минимума в массиве, поскольку хвостовая рекурсия не влияет на сложность алгоритма  
- Вычисление чисел Фибоначчи из-за экспоненциального роста рекурсивных вызовов без мемоизации  
- Быстрая сортировка, так как правильный выбор опорного элемента минимизирует рекурсивные вызовы  
- Бинарный поиск, поскольку его сложность остается логарифмической, даже при рекурсивной реализации  

---

## Вопрос 9  
Какое преимущество B-дерева делает его эффективным для работы с большими объемами данных?  

- Ограничение глубины при добавлении элементов  
- Минимизация числа операций доступа к диску  
- Поддержка параллельной обработки операций  
- Оптимизация работы с операциями удаления  
- Использование фиксированного количества узлов  

---

## Вопрос 10  
Какой алгоритм наиболее эффективен для нахождения максимального потока в транспортной сети?  

- Алгоритм Флёри  
- Алгоритм Прима  
- Алгоритм Дейкстры  
- Алгоритм Форда-Фалкерсона  
- Алгоритм Крускала  

---

## Вопрос 11  
Какой из перечисленных факторов гарантированно ухудшит производительность хеш-таблицы?  

- Сокращение размера хеш-таблицы ниже критической рекомендуемой ёмкости  
- Применение сложной хеш-функции с высокой вычислительной нагрузкой  
- Применение метода цепочек при увеличенной длине бакетов  
- Использование быстрой современной хеш-функции с равномерным распределением  
- Резкое повышение коэффициента заполнения хеш-таблицы свыше нормы  

---

## Вопрос 12  
Какую проблему решает динамическое программирование по сравнению с наивной рекурсией?  

- Снижает вероятность переполнения стека благодаря использованию эффективных структур данных  
- Оптимизирует использование памяти за счет уменьшения количества создаваемых переменных  
- Использует жадный подход для быстрого поиска оптимального решения  
- Уменьшает сложность кода, делая его более читаемым и управляемым в больших проектах  
- Сокращает повторные вычисления за счет мемоизации и кэширования ранее найденных результатов  

---

## Вопрос 13  
В системе очередей на сервере обработки данных произошло снижение производительности.  
Администраторы заметили, что при значительном увеличении числа запросов количество ресурсов процессора и памяти остается стабильным, но время выполнения запросов растет.  

Какой из перечисленных факторов может объяснить увеличение времени выполнения запросов при неизменном потреблении ресурсов?  

- Конфликт между потоками, обслуживающими очередь, замедляет выполнение операций  
- Потеря данных в очереди вызывает необходимость повторных операций  
- Размер стека вызовов превышает допустимый предел, что приводит к ошибкам в обработке  
- Очередь операций достигает предельного размера, создавая дополнительную задержку  
- Недостаточная частота процессора приводит к увеличению времени выполнения операций  

---

## Вопрос 14  
При обработке большого объема данных входные элементы, ранее равномерно распределенные, теперь сгруппированы в кластеры, что вызывает перераспределение нагрузки на этапах сортировки.  

Как это может повлиять на производительность сортировки с точки зрения временной сложности?  

- В кластеризованной выборке алгоритм сможет быстрее обработать частично упорядоченные сегменты  
- Кластеризация данных потребует большего объема памяти при обработке  
- Кластеризация входных данных может снизить эффективность сортировки из-за увеличения числа перестановок  
- Равномерное распределение элементов усложнит предсказание точек разбиения при разделении  
- Кластеризация не повлияет на временную сложность, но изменит порядок выполнения операций  

---

## Вопрос 15  
У вас в работе есть несортированный массив чисел, и вам нужно найти k-й по величине элемент.  

Какой из подходов будет наиболее эффективным с точки зрения временной сложности?  

- Применить сортировку кучей и выбрать k-й элемент  
- Использовать линейный поиск для нахождения k-го элемента  
- Использовать частичную быструю сортировку  
- Отсортировать массив и выбрать k-й элемент  
- Построить сбалансированное двоичное дерево поиска  

---

## Вопрос 16  
Вы реализовали структуру данных на основе связного списка, чтобы эффективно обрабатывать динамические данные. Однако при увеличении числа элементов вы заметили замедление операций поиска и вставки.  

Какой из перечисленных факторов может объяснить это замедление?  

- Некорректная работа внутреннего кэширования данных  
- Повышение временной сложности из-за использования нелинейного поиска  
- Переполнение выделенного блока памяти при динамическом добавлении элементов  
- Частые перемещения элементов в памяти из-за фиксированной структуры данных  
- Увеличение линейной сложности поиска при росте числа элементов  

---

## Вопрос 17  
Вы создаете модуль для приложения, которое управляет инвентарем в складской системе. Каждый новый объект инвентаря должен быть уникальным, и программа должна быстро находить его по номеру. Однако структура данных также должна быть способна добавлять новые элементы с минимальной задержкой. Нас интересует поведение в среднем случае работы хеш-таблицы.  

Что обязательно произойдет, если хеш-таблица будет использоваться для поиска уникальных элементов и добавления новых записей?  

- Разреженность после частых удалений может увеличить длину пробирования и затраты хеша  
- Перехеширование таблицы потенциально может кратковременно замедлять операции вставки  
- Записи будут добавляться и находиться амортизированно за \( O(1) \) даже при большом объёме данных  
- Высокая стоимость вычисления хеш-функции станет узким местом при масштабировании нагрузки  
- При плохой хеш-функции время поиска возрастет резко до линейного  

---

## Вопрос 18  
Какой метод наиболее эффективен для нахождения компонент сильной связности в ориентированном графе?  

- Алгоритм Прима  
- Алгоритм Флойда-Уоршелла  
- Алгоритм Дейкстры  
- Алгоритм Крускала  
- Алгоритм Косарайю  

---

## Вопрос 19  
Вы работаете с набором строковых данных, содержащих повторяющиеся элементы. Ваша задача — эффективно удалить дубликаты и получить список уникальных строк.  

Какой подход позволит добиться этого с минимальными затратами времени?  

- Использовать дерево поиска для вставки и извлечения уникальных строк  
- Применить хеш-таблицу для хранения только уникальных строк  
- Проверить каждую строку на уникальность через последовательный перебор  
- Отсортировать строки и удалить повторяющиеся  
- Применить алгоритм подсчета для быстрой сортировки и удаления дубликатов  

---

## Вопрос 20  
Ваше приложение обрабатывает поток данных в реальном времени. Необходимо быстро выполнять точечные и диапазонные запросы, и часто вставлять новые элементы. Раньше данные хранились в отсортированном массиве и искались бинарным поиском, но с ростом объёма и частыми вставками такой подход стал неприемлемо медленным.  

Какое решение позволит сохранить высокую производительность?  

- Использовать сбалансированное дерево поиска с гарантированной логарифмической сложностью  
- Разбить поток на части и применять параллельную обработку с локальной сортировкой  
- Применить хеш-таблицу с приоритетом на точечный доступ, отказавшись от упорядоченного хранения  
- Хранить данные в отсортированном списке с буферной вставкой и периодическим обновлением  
- Использовать двоичную кучу для ускорения вставок и получения минимального элемента  

---

## Вопрос 21  
Система сообщений использует очередь для управления задачами пользователей. После увеличения числа пользователей некоторые сообщения стали обрабатываться с заметной задержкой, хотя система остается в стабильном состоянии.  

Что может быть причиной задержки в обработке сообщений, если система остается стабильной?  

- Долгое ожидание в очереди из-за возрастающего числа входящих сообщений  
- Недостаточное время ожидания между попытками повторной отправки сообщений  
- Неравномерное распределение потоков на уровне операционной системы  
- Применение устаревшей версии протокола обработки данных  
- Повышенное количество операций записи в базу данных  

---

## Вопрос 22  
Какой способ позволяет преобразовать рекурсивную функцию в итеративную без изменения логики?  

- Применение динамического программирования для уменьшения глубины рекурсии  
- Использование предварительного сканирования для снижения количества вызовов  
- Разделение задачи на несколько независимых частей с передачей промежуточных результатов  
- Использование стека для хранения и управления промежуточными состояниями рекурсии  
- Замена вложенных вызовов на последовательную обработку данных  

---

## Вопрос 23  
Какое основное свойство красно-черного дерева обеспечивает его сбалансированность?  

- Ограничение разницы глубины черных и красных поддеревьев  
- Контроль высоты дерева с учётом красных и черных узлов после каждой вставки  
- Поддержание строгих цветовых ограничений в узлах  
- Использование четных уровней для балансировки красных и черных узлов  
- Применение перекрашивания при изменении структуры дерева  

---

## Вопрос 24  
В процессе работы с хеш-таблицей, использующей двойное хеширование для разрешения коллизий, разработчики заметили, что после удаления нескольких элементов время поиска оставшихся данных значительно увеличилось.  

По какой причине это могло произойти, если таблица имела высокий коэффициент загрузки и не выполнялось рехеширование после удаления записей?  

- Двойное хеширование перезаписывает старые значения, что делает некоторые данные недоступными  
- Удаление элементов привело к изменению распределения хеш-значений, увеличив шаги пробирования  
- Удаленные элементы оставили пробелы, нарушив логику перехода к следующим позициям  
- Каждое удаление требует перерасчёта всех хеш-значений, увеличивая время поиска  
- Из-за высокого коэффициента загрузки возросло число коллизий и длина цепочек  

---

## Вопрос 25  
Вы реализовали структуру данных на основе связного списка для обработки динамических данных. Однако при увеличении числа элементов вы заметили замедление операций поиска и вставки.  

Какой из перечисленных факторов может объяснить это замедление?  

- Увеличение линейной сложности поиска при росте числа элементов  
- Частые перемещения элементов в памяти из-за фиксированной структуры данных  
- Повышение временной сложности из-за использования нелинейного поиска  
- Переполнение выделенного блока памяти при динамическом добавлении элементов  
- Некорректная работа внутреннего кэширования данных  

---

## Вопрос 26  
Какой алгоритм наиболее эффективен для поиска минимального остовного дерева в связном взвешенном графе?  

- Алгоритм Флойда-Уоршелла  
- Алгоритм Дейкстры  
- Алгоритм Тарьяна  
- Алгоритм Беллмана-Форда  
- Алгоритм Прима  

---

## Вопрос 27  
Какое из утверждений о хеш-таблицах НЕВЕРНОЕ?  

- Хеш-таблицы могут использоваться для хранения исключительно числовых данных  
- Хеш-таблицы обеспечивают быстрый доступ к данным за счет прямой адресации по хеш-ключу  
- Использование хорошей хеш-функции снижает вероятность коллизий и повышает эффективность поиска  
- Коэффициент загрузки влияет на производительность хеш-таблицы и частоту рехеширования  
- Открытая адресация и метод цепочек — два основных способа разрешения коллизий в хеш-таблицах  

---

## Вопрос 28  
Какой критерий позволяет определить, что задача может быть решена с помощью алгоритмов динамического программирования?  

- Решение требует использования поиска в глубину для обхода возможных состояний системы  
- Задача может быть разбита на перекрывающиеся подзадачи с повторяющимися вычислениями  
- Задача требует минимизации использования памяти и быстрого доступа к данным  
- Все входные данные известны заранее и не изменяются в процессе выполнения алгоритма  
- Оптимальное решение всегда может быть найдено с помощью последовательных вычислений  
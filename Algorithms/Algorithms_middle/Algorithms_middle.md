# Algorithms_middle

## Вопрос 1  
У вас есть массив данных, который часто обновляется: добавляются новые элементы, удаляются устаревшие. Нужно поддерживать его частично отсортированным для ускорения выборки.  
Какой метод позволит наилучшим образом поддерживать частично отсортированный массив?  

- Применить сортировку вставками для поддержания порядка  
- Использовать двоичное дерево поиска с балансировкой  
- Сортировать весь массив после каждой вставки  
- Ограничить количество изменений и использовать полный пересчет массива  
- Применить алгоритм слияния для обновления массива  

---

## Вопрос 2  
Вы разрабатываете алгоритм для обработки огромных текстовых файлов. Задача — найти определенную подстроку в тексте с минимальными затратами времени.  
Какой из перечисленных алгоритмов применить, чтобы обеспечить наилучшую асимптотическую сложность при поиске подстроки?  

- Префиксное дерево \( O(nm) \)  
- Линейный поиск \( O(nm) \)  
- Алгоритм Рабина-Карпа \( O(n) \)  
- Кнут-Моррис-Пратт \( O(n) \)  
- Поиск с использованием кеш-таблиц \( O(log n) \)  

---

## Вопрос 3  
При разработке кэша в многопоточной системе разработчики обнаружили, что при одновременной записи нескольких потоков в хеш-таблицу некоторые записи теряются или изменяются некорректным образом.  
Выберите наиболее вероятное объяснение, почему это произошло:  

- Хеш-функция создает одинаковые значения для разных потоков, что приводит к перезаписи данных  
- Отсутствие механизма синхронизации привело к состояниям гонки при обновлении записей  
- Динамическое увеличение размера таблицы привело к тому, что старые записи стали недоступны  
- Удаление записей в многопоточной среде приводит к некорректному изменению связей между элементами  
- Таблица использует линейное пробирование, что увеличивает время поиска при большом количестве коллизий  

---

## Вопрос 4  
Вы разрабатываете многопоточное приложение, в котором стек используется для обработки данных.  
Дав высокую нагрузку на стек, вы замечаете некорректное поведение: некоторые элементы в стеке теряются или оказываются добавленными несколько раз.  
Выберите наиболее вероятное объяснение, почему это произошло:  

- Семафоры не обеспечивают последовательность выполнения операций, из-за чего при высокой конкуренции потоки могут некорректно изменять структуру данных  
- Мьютексы не предотвращают ситуации, когда несколько потоков одновременно изменяют стек, создавая возможность гонки данных  
- Барьеры памяти не гарантируют атомарность операций со стеком, что приводит к состояниям, когда один поток не видит обновлений, сделанных другим  
- Блокировки на уровне ядра замедляют выполнение и создают проблемы с корректностью работы многопоточного стека  
- Копирование при записи откладывает модификацию данных до записи, но не предотвращает одновременный доступ нескольких потоков  

---

## Вопрос 5  
В процессе работы с хеш-таблицей, использующей двойное хеширование для разрешения коллизий, разработчики заметили, что после удаления нескольких элементов время поиска оставшихся данных значительно увеличилось.  
По какой причине это могло произойти, если таблица имела высокий коэффициент загрузки и не выполнялось рехеширование после удаления записей?  

- Удаление элементов привело к изменению распределения всех хеш-значений, из-за чего поиск теперь требует больше шагов пробирования  
- Удаленные элементы оставили «дыры» в таблице, и двойное хеширование больше не может корректно переходить к следующим позициям  
- Каждое удаление требует перерасчёта всех хеш-значений, что увеличивает во много раз время поиска других оставшихся элементов таблицы  
- Из-за высокого коэффициента загрузки таблицы возросло число коллизий, что привело к значительному увеличению длины цепочек в бакетах  
- Двойное хеширование перезаписывает старые значения, что делает некоторые данные полностью недоступными после удаления записей  

---

## Вопрос 6  
Вы используете в алгоритме связный список для управления структурой очереди обработки задач. В какой-то момент оказалось, что в некоторых случаях задачи не достигают завершения.  
Что из перечисленного могло стать причиной такого поведения?  

- Отсутствие сортировки в хранимых данных  
- Случайное распределение данных в памяти  
- Ограниченный размер начального выделенного блока памяти  
- Неправильное обновление ссылок при удалении узлов  
- Низкая эффективность хеширования в больших структурах  

---

## Вопрос 7  
Какая техника оптимизации рекурсивных вызовов помогает избежать лишних вычислений?  

- «Разделяй и властвуй» для уменьшения накладных расходов  
- Мемоизация, позволяющая повторно использовать уже вычисленные значения  
- Оптимизация структуры данных с целью ускорения вычислений  
- Хеширование для ускорения поиска данных в рекурсивных вызовах  
- Использование глубокой рекурсии для сокращения количества шагов  

---

## Вопрос 8  
Какой из приведенных алгоритмов неэффективен при использовании рекурсии?  

- Факторизация числа, поскольку сложность разложения не зависит от многопоточности  
- Поиск минимума в массиве, поскольку хвостовая рекурсия не влияет на сложность алгоритма  
- Вычисление чисел Фибоначчи из-за экспоненциального роста рекурсивных вызовов без мемоизации  
- Быстрая сортировка, так как правильный выбор опорного элемента минимизирует рекурсивные вызовы  
- Бинарный поиск, поскольку его сложность остается логарифмической, даже при рекурсивной реализации  

---

## Вопрос 9  
Какое преимущество B-дерева делает его эффективным для работы с большими объемами данных?  

- Ограничение глубины при добавлении элементов  
- Минимизация числа операций доступа к диску  
- Поддержка параллельной обработки операций  
- Оптимизация работы с операциями удаления  
- Использование фиксированного количества узлов  

---

## Вопрос 10  
Какой алгоритм наиболее эффективен для нахождения максимального потока в транспортной сети?  

- Алгоритм Флёри  
- Алгоритм Прима  
- Алгоритм Дейкстры  
- Алгоритм Форда-Фалкерсона  
- Алгоритм Крускала  

---

## Вопрос 11  
Какой из перечисленных факторов гарантированно ухудшит производительность хеш-таблицы?  

- Сокращение размера хеш-таблицы ниже критической рекомендуемой ёмкости  
- Применение сложной хеш-функции с высокой вычислительной нагрузкой  
- Применение метода цепочек при увеличенной длине бакетов  
- Использование быстрой современной хеш-функции с равномерным распределением  
- Резкое повышение коэффициента заполнения хеш-таблицы свыше нормы  

---

## Вопрос 12  
Какую проблему решает динамическое программирование по сравнению с наивной рекурсией?  

- Снижает вероятность переполнения стека благодаря использованию эффективных структур данных  
- Оптимизирует использование памяти за счет уменьшения количества создаваемых переменных  
- Использует жадный подход для быстрого поиска оптимального решения  
- Уменьшает сложность кода, делая его более читаемым и управляемым в больших проектах  
- Сокращает повторные вычисления за счет мемоизации и кэширования ранее найденных результатов  

---

## Вопрос 13  
В системе очередей на сервере обработки данных произошло снижение производительности.  
Администраторы заметили, что при значительном увеличении числа запросов количество ресурсов процессора и памяти остается стабильным, но время выполнения запросов растет.  

Какой из перечисленных факторов может объяснить увеличение времени выполнения запросов при неизменном потреблении ресурсов?  

- Конфликт между потоками, обслуживающими очередь, замедляет выполнение операций  
- Потеря данных в очереди вызывает необходимость повторных операций  
- Размер стека вызовов превышает допустимый предел, что приводит к ошибкам в обработке  
- Очередь операций достигает предельного размера, создавая дополнительную задержку  
- Недостаточная частота процессора приводит к увеличению времени выполнения операций  

---

## Вопрос 14  
При обработке большого объема данных входные элементы, ранее равномерно распределенные, теперь сгруппированы в кластеры, что вызывает перераспределение нагрузки на этапах сортировки.  

Как это может повлиять на производительность сортировки с точки зрения временной сложности?  

- В кластеризованной выборке алгоритм сможет быстрее обработать частично упорядоченные сегменты  
- Кластеризация данных потребует большего объема памяти при обработке  
- Кластеризация входных данных может снизить эффективность сортировки из-за увеличения числа перестановок  
- Равномерное распределение элементов усложнит предсказание точек разбиения при разделении  
- Кластеризация не повлияет на временную сложность, но изменит порядок выполнения операций  

---

## Вопрос 15  
У вас в работе есть несортированный массив чисел, и вам нужно найти k-й по величине элемент.  

Какой из подходов будет наиболее эффективным с точки зрения временной сложности?  

- Применить сортировку кучей и выбрать k-й элемент  
- Использовать линейный поиск для нахождения k-го элемента  
- Использовать частичную быструю сортировку  
- Отсортировать массив и выбрать k-й элемент  
- Построить сбалансированное двоичное дерево поиска  

---

## Вопрос 16  
Вы реализовали структуру данных на основе связного списка, чтобы эффективно обрабатывать динамические данные. Однако при увеличении числа элементов вы заметили замедление операций поиска и вставки.  

Какой из перечисленных факторов может объяснить это замедление?  

- Некорректная работа внутреннего кэширования данных  
- Повышение временной сложности из-за использования нелинейного поиска  
- Переполнение выделенного блока памяти при динамическом добавлении элементов  
- Частые перемещения элементов в памяти из-за фиксированной структуры данных  
- Увеличение линейной сложности поиска при росте числа элементов  

---

## Вопрос 17  
Вы создаете модуль для приложения, которое управляет инвентарем в складской системе. Каждый новый объект инвентаря должен быть уникальным, и программа должна быстро находить его по номеру. Однако структура данных также должна быть способна добавлять новые элементы с минимальной задержкой. Нас интересует поведение в среднем случае работы хеш-таблицы.  

Что обязательно произойдет, если хеш-таблица будет использоваться для поиска уникальных элементов и добавления новых записей?  

- Разреженность после частых удалений может увеличить длину пробирования и затраты хеша  
- Перехеширование таблицы потенциально может кратковременно замедлять операции вставки  
- Записи будут добавляться и находиться амортизированно за \( O(1) \) даже при большом объёме данных  
- Высокая стоимость вычисления хеш-функции станет узким местом при масштабировании нагрузки  
- При плохой хеш-функции время поиска возрастет резко до линейного  

---

## Вопрос 18  
Какой метод наиболее эффективен для нахождения компонент сильной связности в ориентированном графе?  

- Алгоритм Прима  
- Алгоритм Флойда-Уоршелла  
- Алгоритм Дейкстры  
- Алгоритм Крускала  
- Алгоритм Косарайю  
# **Docker\_middle**

**Вопрос 1**

Вы запускаете контейнер с помощью команды: docker run \-it ubuntu \--rm

Ожидалось, что контейнер запустится и автоматически удалится после завершения работы.

Однако команда завершается с ошибкой, и контейнер даже не создается.

В чем причина ошибки при запуске?

1. Образ ubuntu в целом осуществляет автоматическое удаление контейнеров таким способом  
2. Для использования флага \--rm требуется обязательно использовать docker-compose  
3. Флаг \--rm указан после имени образа, поэтому Docker CLI считает его не валидным  
4. Интерактивный режим \-it в команде docker run \-it ubuntu \--rm несовместим с автоматическим удалением  
5. Системный демон Docker не поддерживает в команде docker run \-it ubuntu флаг \--rm

**Вопрос 2**

При разработке Dockerfile для веб\-приложения в облаке вы столкнулись с проблемами:

* Итоговый образ увеличился на 30% по размеру.  
* Сборка образа стала медленнее почти в два раза.  
* Внутри образа остались временные файлы после выполнения apt-get update и apt-get install.

Какой метод написания Dockerfile объясняет, почему объединение всех команд установки и удаления временных файлов в рамках одной инструкции RUN решает все три проблемы одновременно?

1. Каждая команда устанавливается отдельно, что ускоряет диагностику ошибок при сборке  
2. Удаление временных файлов в отдельной инструкции позволяет упростить их поиск в процессе отладки  
3. Вынос удаления временных файлов в отдельный этап помогает сохранить порядок в структуре Dockerfile  
4. Все изменения выполняются в одном слое, временные файлы удаляются до фиксации слоя, что уменьшает размер и ускоряет сборку  
5. Создание дополнительных слоев через несколько инструкций RUN увеличивает возможности кэширования

**Вопрос 3**

Вы используете следующий Docker Compose файл:

version: '3.8'  
services:  
  api:  
    image: myapi:latest  
    environment:  
      API\_KEY: key123  
  redis:  
    image: redis:latest

При запуске контейнеров сервис api не может подключиться к redis, а в логах сервиса api фиксируются ошибки соединения с сетью.

Что поможет решить эту проблему?

1. Добавить переменные окружения для сервиса redis и подключение обоих сервисов к одной сети  
2. Перезапуск Compose файла с флагом \--force-recreate и подключение двух сервисов к одной сети  
3. Смена версии Compose файла на 2.1 и подключение обоих сервисов к одной сети  
4. Удаление настройки environment из сервиса api и подключение сервисов к одной сети  
5. Добавление секции networks в Compose файл и подключение сервисов к одной сети

**Вопрос 4**

Вы разворачиваете распределённое приложение в Docker Swarm. Контейнеры должны быть развернуты как сервисы и иметь возможность взаимодействовать друг с другом вне зависимости от того, на каких узлах они находятся.

Что вы должны использовать для настройки сети и запуска контейнеров?

1. Команду docker run \--net-host для каждого контейнера, чтобы подключить их к сети хоста  
2. Сеть overlay и команду docker service create для развертывания контейнеров  
3. Сеть custom и команду docker network connect, чтобы подключить все контейнеры  
4. Сеть macvlan и команду docker network create, чтобы дать контейнерам собственные MAC- и IP-адреса  
5. Сеть bridge и команду docker network create для создания сети, а затем подключить контейнеры к этой сети

**Вопрос 5**

Контейнер web-app начал перегружать CPU до 100%. Ваша задача:

1. Определить, какие процессы внутри контейнера создают наибольшую нагрузку.  
2. Получить текущие метрики использования памяти, CPU и сетевых ресурсов.  
3. Скопировать файл логов /var/log/app.log на хост в директорию /tmp для последующего анализа.

Условие: Интерактивный вход в контейнер использовать нельзя.

1. Запустить docker logs \--tail 100 для просмотра последних ошибок, использовать docker exec для анализа процессов и затем скопировать файл через docker cp  
2. Остановить контейнер через docker stop, сохранить состояние через docker commit и скопировать файл через docker cp  
3. Выполнить docker kill для немедленного завершения контейнера, затем собрать логи через docker logs и скопировать их через docker cp  
4. Использовать docker inspect для получения состояния контейнера, затем docker cp для копирования логов и docker logs для диагностики  
5. Использовать docker top для процессов, docker stats для метрик и docker cp для копирования файлов

**Вопрос 6**

Вы настраиваете тестовое окружение для микросервисного приложения. Требуется развернуть локальный Docker Registry, который будет доступен только из локальной сети. При этом необходимо:

* обеспечить запуск на порту 5000  
* исключить доступ извне  
* предотвратить несанкционированную публикацию образов

Какая конфигурация запуска и настройка среды обеспечит выполнение всех этих условий?

1. Ограничить внешний доступ к Registry через правила фаервола и настроить запуск контейнера с публикацией порта 5000\.  
2. Запустить Docker Registry с флагом \--insecure-registry, чтобы упростить доступ внутри сети  
3. Использовать сеть host, чтобы скрыть порт от внешней среды  
4. Запустить Docker Registry на произвольном порту и использовать NAT для фильтрации доступа  
5. Развернуть Docker Registry в сети bridge и использовать переменную REGISTRY\_HTTP\_ADDR=0.0.0.0:5000

**Вопрос 7**

Контейнер backend-api, использующий данные из оперативной памяти, завис. Вам необходимо:

1. Временно заморозить его выполнение для дампа состояния.  
2. После анализа возобновить работу без потери данных.  
3. При критической ошибке — аварийно завершить контейнер немедленно.  
4. Настроить автоматический перезапуск контейнера через политику restart=always и завершить его вручную при необходимости  
5. Остановить контейнер через docker stop, создать дамп состояния вручную и перезапустить через docker start  
6. Использовать docker-compose pause для паузы, docker-compose unpause для восстановления и docker kill для завершения  
7. Выполнить docker wait для ожидания завершения контейнера, сохранить дамп состояния через внешний процесс и завершить через docker kill  
8. Приостановить через docker pause, возобновить через docker unpause, завершить через docker kill

**Вопрос 8**

Какой способ подключения связанного тома для сохранения данных контейнера НЕ поможет для успешной работы с ним?

1. Применение bind-монтирования с \--mount type=bind, привязывая директорию хоста к контейнеру  
2. Добавление параметра VOLUME в Dockerfile для автоматического создания тома без явной привязки  
3. Использование временной файловой системы \--tmpfs, где данные хранятся в оперативной памяти  
4. Использование тома, созданного через docker volume create, с последующей его привязкой к контейнеру с флагом \-v  
5. Использование сети для хранения данных через NFS или CIFS, монтируя их в контейнер

**Вопрос 9**

Вы администрируете систему, где контейнер Nginx используется для хранения логов. Эти логи содержат информацию о действиях пользователей и системных событиях, которые важны для анализа и диагностики. Вам нужно регулярно сохранять их копии в отдельную директорию на хосте, чтобы избежать потери данных при сбое контейнера. Также важно, чтобы процесс резервного копирования не прерывал работу Nginx и оставался полностью автоматизированным.

Выберите подходящий метод.

1. Настроить задачу cron для автоматического копирования логов из контейнера на хост  
2. Настроить контейнер Nginx в режиме read-only для полной защиты данных пользователей  
3. Подключить том Docker к контейнеру Nginx и настроить синхронизацию с хостовой системой  
4. Сохранять логи внутри файловой системы контейнера Nginx без подключения тома  
5. Использовать параметр \--restart=no для контейнера Nginx, чтобы периодически его перезапускать

**Вопрос 10**

Какой инструмент позволяет эффективно собирать и анализировать журналы из множества контейнеров в кластере?

1. Docker CLI  
2. Grafana  
3. Fluentd  
4. Elastic Stack  
5. Prometheus

**Вопрос 11**

Вы анализируете производительность микросервисного приложения в Docker-контейнерах с использованием Grafana и Elastic Stack. Один из сервисов начал работать медленнее, чем ожидалось, а логи показывают регулярные таймауты. Мониторинг фиксирует высокие задержки при взаимодействии с базой данных: трафик идет через виртуальные интерфейсы bridge-сети Docker и NAT, что дает дополнительную прослойку.

Что произойдет, если заменить стандартную сеть Docker bridge на host?

1. Таймауты при взаимодействии с базой данных могут сохраняться, если проблема связана с ограничением ресурсов хоста  
2. Задержки при взаимодействии с базой данных уменьшатся, так как сеть host упрощает маршрутизацию  
3. Пропадет возможность изолировать сеть контейнеров, так как сеть host напрямую использует сетевые интерфейсы хоста  
4. Проблема лимита подключений к базе данных останется, так как она не связана с типом сети Docker  
5. Скорость взаимодействия между контейнерами повысится, так как сеть host устраняет часть сетевых накладных расходов

**Вопрос 12**

В Jenkins-пайплайне используется Docker для запуска тестовой среды в изолированном контейнере.

Какое основное преимущество дает автоматизация тестирования в Docker-контейнере по сравнению с ручной настройкой окружения на каждой машине?

1. Docker позволяет создать изолированное окружение для тестов без влияния на основную систему Jenkins  
2. Docker упрощает настройку агрегации тестовых отчетов, но не исключает конфигурацию приложений для их создания  
3. Docker уменьшает объем тестовых сценариев с плагинами Jenkins, ускоряя работу пайплайна  
4. В Jenkins-пайплайне Docker устраняет необходимость проверки кода перед его сборкой  
5. Docker позволяет автоматически подтягивать образы с актуальными зависимостями для тестирования